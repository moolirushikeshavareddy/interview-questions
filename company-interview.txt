								INTERVIEW COMPANIES
								----------------------

A)Congizant : ROUND-1 (terraform,jenkins,ansible,prometheus,garfana,aws,sonarqube,python)
-------- DEVOPS ROLE(Jenkins, Terraform,AWS) --------
1)what is state file in terraform ?
2)where you will store it in remote or local ?
3)how can you retrive if your state file is corrupted ?
4)how can you write a terraform file ?
5)tell me about pipeline in jenkins ?
6)how will you configure sonarqube ?
7)where you will store credentails in jenkins ?
8)how you will write pipleline syntax ?
9)how you will configure ssh in ansible ?
10)how you will write the code in ansible ?
11)basic syntax for ansible playbook ?
12)you have to install an application in production but it doesnt give access to outside, how you will do it ?
13)what is inventory file ?
14)do you know bigbucket ?
15)how you will configure prometheus ?
16)how you will create dashboard in grafana ?
17)how you will see the logs in grafana ?
18)artifact is downloading from s3 to production but is not executing, how you can slove it ?
19)what are the providers in terraform, is there any other providers you can use in terraform ?
20)what is import in terraform ?
21)how will you configure to tomcat in jenkins ?
22)i have structured data and non-structured data, how will you compare both  in python ?
feedback :
--------
need to improve skills in terraform, jenkins, and prometheus and garfana 




B)Appiness : ROUND-1 (linux,aws,jenkins,rds,prometheus,garfana,docker,docker-compose)
------- DEVOPS ROLE (AWS,Jenkins, Terraform, Linux)--------
1)what are the types of ec2 and explain it ?
2)what is difference between t,m,c series in ec2 ?
3)what are the different types of ec2-instances(cost-priceing) ?
4)how can you make your ec2-instances private ?
5)what is autoscaling groups and templetes and explain its configuration ?
6)what are the types of load balancers and explain them ?
7)how to configure an alb,nlb and targets ?
8)what is IAM ?
9)what is WAF and how you can use it ?
10)i have new user how can i attach full-s3 permission for the user ?
11)explain the policy in pid, resource permissions for the user ?
12)what is s3 ?
13)how many types are there in s3 and explain them ?
14)what is cloudfront ?
15)what is vpc and explain it ?
16)what is the different between nacl and sg and which level they are ?
17)expalin all about vpc like sg,nacl,routes,subnetes etc ?
18)how can i ensure that RDS has high-availability ?
19)how can you configure prometheus and grafana dashboards ?
20)what are the types of metrices you have seen ?
21)how to check logs in prometheus and grafana ?
22)what is jenkins ?
23)how to configure jenkins ?
24)write the declaritive pipeline and explain it ?
25)how many types of builds are there in jenkins ?
26)how you will configure it to nodes ?
27)how you will ensure that the jenkins up and running ?
28)how can you give new user access in jenkins which plugin you need to install ?
29)how can you change the nodes configurations ?
30)what is docker ?
31)explain the architecture of docker ?
32)what is docker prune ?
33)what are the network types and explain them ?
34)how can i access two different containers which is having different networks ?
35)how can i access two same containers with same network ?
36)how can you check docker-logs ?
37)how can you login to container explain the command ?
38)how can you check logs in container ?
39)write DockerFile and explain it ?
40)difference between CMD and ENTRYPOINT ?
41)write a Docker-Compose file and explain it ?
42)what are different types of volumes and explain it ?
43)how can you copy the files or floders which are in host to container ?
44)how can you create a volume and network ?
45)which is default network in docker ?
46)explain the architecture of linux  and explain it (ex : /var ...) ?
47)where logs are stored in linux ?
48)how can you see all metrics in linux (top) ?
49)what are metrics you will see in top ?
50)i want to execute the docker file which permissions you will give ?
51)i want to change the owner-ship of docker file, how can you do it ?
feedback :
---------
almost all question you have answered, check with AWS and Docker, remaining terraform and jenkins no issue






c)Terralogic - Software Development and IT Services Company(docker, kubernetes)
-------------DEVOPS(python, ansible, docker, kubernetes) --------- ----------- --------------- ---------------------------
1)tell me about yourself ?
2)tell me about your project ?
3)what is the motive of this project ?
4)how many years of experence in kubernetes ?
feedback :
--------
we are looking for 3 years of experenece candidate, thankyou !





D)Flipkart : ROUND-1 ()
-------- SRE ROLE (Linux, Terraform, Ansible, python, Bash) -----------
1)tell me about 5 linux commands and explain them ?
2)how to see cpu metrics ?
3)what are the 3 load types in cpu of top command ?
4)how to check all files are open or not ?
5)can we create 2 state files in terraform ?
6)what is statelock ?
7)what is statefile ?
8)what are the 3 main files in terraform ?
9)explain roles in ansible ?
10)what is ansible inventory ?
11)do you know shell scripting, python, ansible if know write the code for the below description ?

Description:

In Flipkart we destroy VMs. Before destroying a VM from production, we want to do a list of checks to avoid production outage and gracefully remove it from rotation. 

Write automation to do the following checks. Automation should be scalable, should be able to run on hundreds of VMs

Your utility will take 1 input file:
Input file will contain this JSON:

Prod-hadoop-dn-002: Check_1, Check_2, Check_3
prod-hadoop-dn-001: Check_1, Check_2
localhost: Check_1

You need to create a small application in any of the scripting languages that will perform the above validation/checks on the linux VMs. On Prod-hadoop-dn-002, Check_1, Check_2, Check_3 will be performed while on prod-hadoop-dn-001 only Check_1, Check_2 will be performed. Check definitions can be found below:
 
Checks: 
Check_1: Ensure datanode service process (Service name: hadoop-hdfs-datanode.service) is not running in the VM

Check_2: The VM (hostname) should not be part of a global active list. And if it is part of the active list, then flag a warning for the node and fail the check. You can retrieve the active list of nodes from an external HTTP endpoint - https://pastebin.com/raw/0hQ2VnwS

Run HTTP request on Hadoop namenode jmx and get list of active nodes 
Http Endpoint - https://pastebin.com/raw/0hQ2VnwS

response :
https://pastebin.com/raw/0hQ2VnwS		
	{
  "LiveNodes": [
    "prod-hadoop-dn-001",
    "prod-hadoop-dn-002",
    "prod-hadoop-dn-003",
    "localhost",
    "127.0.0.1"
  ]
}



Sample output
-------------
{
  "beans": [
    {
      "name": "Hadoop:service=NameNode,name=NameNodeInfo",
      "modelerType": "org.apache.hadoop.hdfs.server.namenode.FSNamesystem",
      "LiveNodes": [
        "prod-hadoop-dn-001",
        "prod-hadoop-dn-002",
        "prod-hadoop-dn-003"
      ]
    }
  ]
}



In the above e.g. prod-hadoop-dn-001, prod-hadoop-dn-002, prod-hadoop-dn-003 are active and these should not be destroyed. Everything other VM can be destroyed

Check_3: Average storage available is > 80% across all the disk mounts
If a VM has 3 disk mounts each having 10%, 20%, 30% available respectively, then the overall average disk availability is 20% for the VM

Assume that disks are of type :,
/dev/xda ( boot disk ) 
/dev/xdb 
..
…

Please exclude the boot disk from calculation. 

Add-on : Scale this model for 1000’s of nodes , and how to handle the aggregated outputs from all the nodes .

Expected output:
For each VM in the input it should say, for each check whether the check passed or failed with warning

Sample Input:
Prod-hadoop-dn-002: Check_1, Check_2, Check_3
prod-hadoop-dn-001: Check_1, Check_2
localhost: Check_1


Output:
localhost Check_1 success
Prod-hadoop-dn-001 Check_1 success
Prod-hadoop-dn-001 Check_2 failed
Prod-hadoop-dn-002 Check_1 success
Prod-hadoop-dn-002 Check_2 failed
Prod-hadoop-dn-002 Check_3 success


Expectation

Code / Script should be modular
Your code should be demo-able on your local dev machine, you can either prepare a test set or the interviewer will provide a test set
You can use the internet for any syntax while coding
Ensure all edge cases are handled e.g. VMs are not sshable, etc




==============================
Code from Rushi:

#! bin/bash 
sudo ps -ef >> file.txt
cat file.txt | rm -rf host* >> file.txt
input = ""
while (file.txt == true){
		if(cat file.txt | input == active >> active.json){
        		echo active.json
        	}
            if(cat file.txt | input == failure >> failure.json){
        		sudo systemctl failure.json
        	}
 }  	
feedback :
---------
need to improve skills in linux basics and shell script writing, ansible and python





e)Sutherland Global (python, json, shell scripting)
------DEVOPS ENGINEER ---------------
question 1 :write a groovy code to convert list into json
-------------
["101":"Ram,Hyderabad,20000","102":"Shyam,Delhi,40000","103":"Divya,Banglore,25000"]

code :
-------
import groovy.json.JsonOutput

def data = [
    "101:Ram,Hyderabad,20000",
    "102:Shyam,Delhi,40000",
    "103:Divya,Banglore,25000"
]

def parsedData = data.collect { entry ->
    def parts = entry.split(':')
    def id = parts[0]
    def details = parts[1].split(',')

    [
        id     : id,
        name   : details[0],
        city   : details[1],
        salary : details[2].toInteger()
    ]
}

def jsonOutput = JsonOutput.toJson(parsedData)
println JsonOutput.prettyPrint(jsonOutput)



question 2: write code to print sum of second last digit in each element
--------------
[13245, 12343, 123435]

code :
-------
def numbers = [13245, 12343, 123435]

def sumSecondLastDigits = numbers.collect { number ->
    def digits = number.toString().toList()*.toInteger()
    digits[-2]  // Extract the second last digit
}.sum()

println "Sum of second last digits: ${sumSecondLastDigits}"



question 3: write a python code to create an api
-----------




f)Ekaggata Technology : SCREENING ROUND -1 (ec2, vpc, asg, lb, route53, iam, lamda, python, shell scripting, terraform)
---------- -----------DEVOPS ROLE (AWS, TERRAFORM, PYTHON, SHELL SCRIPTING) --------------------- ---------------------
1)how many concepts you know in aws ?
2)how many topics you know in terraform ?
3)do you know scripting language ?
4)did you worked with iam and lamda functions ?











